from keras.datasets import mnist
from model import *
from keras.utils import np_utils
from keras.preprocessing.image import ImageDataGenerator

dataset = 'mnist'
batch_size = 128
nb_epoch = 100

if dataset == 'mnist':
    # The data, shuffled and split between train and test sets
    (X_train, y_train), (X_test, y_test) = mnist.load_data()
    nb_classes = 10

print('X_train shape:', X_train.shape)
print(X_train.shape[0], 'train samples')
print(X_test.shape[0], 'test samples')

X_train = X_train.astype('float32')
X_test = X_test.astype('float32')

# convert class vectors to binary class matrices
Y_train = np_utils.to_categorical(y_train, nb_classes)
Y_test = np_utils.to_categorical(y_test, nb_classes)

datagen = ImageDataGenerator(
    featurewise_center=True,
    samplewise_center=False,
    featurewise_std_normalization=True,
    samplewise_std_normalization=False,
    zca_whitening=False,
    rotation_range=0,
    width_shift_range=0.125,
    height_shift_range=0.125,
    horizontal_flip=True,
    vertical_flip=False)
datagen.fit(X_train)

test_datagen = ImageDataGenerator(
    featurewise_center=True,
    samplewise_center=False,
    featurewise_std_normalization=True,
    samplewise_std_normalization=False,
    zca_whitening=False,
    rotation_range=0,
    width_shift_range=0.,
    height_shift_range=0.,
    horizontal_flip=False,
    vertical_flip=False)
test_datagen.fit(X_test)

input_shape = list(X_train.shape)
input_shape[0] = batch_size

model = build_model(input_shape=input_shape, layer_count=1)

# fit the model on the batches generated by datagen.flow()
model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size, shuffle=True),
                        samples_per_epoch=X_train.shape[0],#//batch_size*batch_size, # Hack, TF residual_drop() dislikes non-fixed size batches.
                        nb_epoch=nb_epoch,
                        validation_data=test_datagen.flow(X_test, Y_test, batch_size=batch_size),
                        nb_val_samples=X_test.shape[0]#//batch_size*batch_size, # see above
                        )

# nb_features = 28*28
# # flatten the 28x28 images to arrays of length 28*28:
# X_train = X_train.reshape(60000, nb_features)
# X_test = X_test.reshape(10000, nb_features)

# # convert brightness values from bytes to floats between 0 and 1:
# X_train /= 255
# X_test /= 255



# def vis(X, filename, n=20):
#     w = 28
#     assert len(X) >= n*n
#     X = X[:n*n]
#     X = X.reshape((n, n, w, w))
#     img = np.zeros((n*w, n*w))
#     for i in range(n):
#         for j in range(n):
#             img[i*w:(i+1)*w, j*w:(j+1)*w] = X[i, j, :, :]
#     img = img.clip(0, 255).astype(np.uint8)
#     scipy.misc.imsave(filename, img)

# vis(Y.dot(W) * 255, "k-arm.png")


# print "Average density of nonzero elements in the code: ", np.average(nonzero) / dict_size
# print "Reconstruction error: ", reconsError


# # W = np.load(file("/home/daniel/experiments/k-arm/k-arm/dict.npz"))['arr_0']

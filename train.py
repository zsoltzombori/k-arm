import argparse
import data
from model import *

dataset = 'mnist'

parser = argparse.ArgumentParser(description="Image classifer using sparsifying arm layers.")
parser.add_argument('--iteration', dest="iteration", type=int, default=6, help="Number of iterations in k-arm approximation")
parser.add_argument('--threshold', dest="threshold", type=float, default=0.02, help="Sparsity coefficient")
parser.add_argument('--dict', dest="dict_size", type=int, default=400, help="Size of the feature dictionary")
parser.add_argument('--epoch', dest="epoch", type=int, default=5, help="Number of epochs")
parser.add_argument('--lr', dest="lr", type=float, default=0.001, help="learning rate")
parser.add_argument('--batch', dest="batchSize", type=int, default=16, help="Batch size")
parser.add_argument('--layers', dest="layers", type=int, default=1, help="Arm layer count")
args = parser.parse_args()

print "layers: {}, iteration: {}, threshold: {}, dict_size: {}, lr: {}, batch: {}, epoch: {}".format(args.layers,args.iteration,args.threshold,args.dict_size,args.lr,args.batchSize,args.epoch)
if dataset == 'mnist':
    (X_train, Y_train), (X_test, Y_test), datagen, test_datagen, nb_classes = data.load_mnist()

model = build_classifier(input_shape=X_train.shape, nb_classes=nb_classes, layers=args.layers, lr=args.lr, iteration=args.iteration, threshold=args.threshold, dict_size=args.dict_size)

# fit the model on the batches generated by datagen.flow()
model.fit_generator(datagen.flow(X_train, Y_train, batch_size=args.batchSize, shuffle=True),
                        samples_per_epoch=X_train.shape[0],
                        nb_epoch=args.epoch,
                        validation_data=test_datagen.flow(X_test, Y_test, batch_size=args.batchSize),
                        nb_val_samples=X_test.shape[0]
                        )

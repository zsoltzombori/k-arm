import numpy as np
from arm import ArmLayer
from vis import *
from diff_vis import *
from model import *
import data
import argparse
import re
import os.path
import sys
sys.setrecursionlimit(2**20)

parser = argparse.ArgumentParser(description="Sparse image encoding using k-arm.")
parser.add_argument('--iteration', dest="iteration", type=int, default=1, help="Number of iterations in k-arm approximation")
parser.add_argument('--threshold', dest="threshold", type=float, default=0.5, help="Sparsity coefficient")
parser.add_argument('--dict', dest="dict", type=int, default=1000, help="Size of the feature dictionary")
parser.add_argument('--epoch', dest="epoch", type=int, default=10, help="Number of epochs")
parser.add_argument('--weightFile', dest="weightFile", default=None, help="dictionary matrix file")
parser.add_argument('--lr', dest="lr", type=float, default=0.001, help="learning rate")
parser.add_argument('--trainSize', dest="trainSize", type=int, default=20000, help="Training set size")
parser.add_argument('--testSize', dest="testSize", type=int, default=2000, help="Test set size")
parser.add_argument('--batch', dest="batchSize", type=int, default=128, help="Batch size")
parser.add_argument('--resultFile', dest="resultFile", default=None, help="File to write results")
args = parser.parse_args()
dict_size = args.dict
iteration = args.iteration
threshold = args.threshold
nb_epoch = args.epoch
trainSize = args.trainSize
testSize = args.testSize 
batch_size=args.batchSize
weightFile = args.weightFile
resultFile = args.resultFile
lr = args.lr


(X_train, Y_train), (X_test, Y_test), datagen, test_datagen, nb_classes = data.load_mnist()
X_train = X_train[:trainSize]
X_test = X_test[:testSize]
vis(X_test * 255, "orig.png")
nb_features = np.prod(X_test.shape[1:])

if weightFile is not None:
    weights = np.load(file(weightFile))['arr_0']
    trainIteration = re.search('it(.+?)_', weightFile).group(1)
    trainThreshold = re.search('th(.+?).npz', weightFile).group(1)
else:
    weights = None
    trainIteration = 0
    trainTheshold = 0

model = build_encode_decode_layer(input_shape=X_test.shape, iteration=iteration, threshold=threshold, dict_size=dict_size, weights=weights, lr=lr)

#fit the model on the batches generated by datagen.flow()
model.fit_generator(datagen.flow(X_train, X_train, batch_size=batch_size, shuffle=True),
                        samples_per_epoch=X_train.shape[0],
                        nb_epoch=nb_epoch,
                        validation_data=test_datagen.flow(X_test, X_test, batch_size=batch_size),
                        nb_val_samples=X_test.shape[0]
                        )


y_fun = K.function([model.layers[0].input], [model.layers[1].output])
Y_learned = y_fun([X_test])[0]
X_prime_learned = model.predict_on_batch(X_test)

nonzero = np.apply_along_axis(np.count_nonzero, axis=1, arr=Y_learned)
nonzeroHist = np.histogram(nonzero, bins=20)
print nonzeroHist[0]
print nonzeroHist[1]
print "Average density of nonzero elements in the code: ", np.average(nonzero) / dict_size
nonzeroInt = int(np.average(nonzero))
print "Average number of nonzero elements in the code: ", nonzeroInt
reconsError = np.sum(np.square(X_prime_learned-X_test)) / testSize / nb_features
print "Reconstruction error: ", reconsError
sparsity_loss = threshold * np.sum(np.abs(Y_learned)) / testSize / nb_features
total_loss = reconsError + sparsity_loss
print "Total loss: ", total_loss

outputFile = "output/lista_it{}_th{}_dict{}_lr{}_train{}_test{}_batch{}_epoch{}_loss{:.3f}.png".format(iteration,threshold,dict_size,lr,trainSize,testSize,batch_size,nb_epoch,total_loss)
vis(X_prime_learned * 255, outputFile)
diff_vis(X_test[:400],X_prime_learned[:400],28,28,20,20,"output/lista_diff")


W_learned = model.layers[1].get_weights()[0]
W_scaled = W_learned - np.min(W_learned)
W_scaled /= np.max(W_scaled)
W_scaled *= 255
vis(W_scaled, "lista_dict.png", n=int(np.sqrt(dict_size)))

# the the weight matrix was trained from random, then save it
if weightFile is None:
    with file("dict/it{}_th{}.npz".format(iteration,threshold), "wb") as npzfile:
        np.savez(npzfile, W_learned)

# if resultFile was provided then add new line to result file
if resultFile is not None:
    if os.path.exists(resultFile):
        with open(resultFile, "a") as file:
            file.write("{},{},{},{},{}\n".format(trainIteration,trainThreshold,iteration,threshold,total_loss))
    else:
        with open(resultFile, "w") as file:
            file.write("TrainIteration,TrainThreshold,Iteration,Threshold,Loss\n")
            file.write("{},{},{},{},{}\n".format(trainIteration,trainThreshold,iteration,threshold,total_loss))
